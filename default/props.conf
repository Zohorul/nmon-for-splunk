# props.conf

##################################
#			nmon2csv stanza			#
##################################

# IMPORTANT: Since the V1.6.0, the configuration uses the nmon2csv.sh wrapper that will call nmon2csv.py (prefered choice) or nmon2csv.pl if appropriated
# You can still force the configuration to use the Python or Perl converter (but the nmon2csv.sh wrapper will do the choice for you, enforcing the choice is not required anymore)

# *** BE UPGRADE RESILIENT: *** Copy this stanza to your local/props.conf to prevent futur upgrades from overwriting your setting

# To force the use of the Python converter, set:
# unarchive_cmd = $SPLUNK_HOME/bin/splunk cmd python $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.py

# To force the use of the Python converter, set:
# unarchive_cmd = $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.pl

# This source stanza will be called by the archive processor to convert NMON raw data into csv files
# Splunk can manage. See inputs.conf for the associated monitor

# To force nmon2csv parsers to always consider nmon files as realtime data, you can set the option "--mode realtime":
# unarchive_cmd = $SPLUNK_HOME/bin/splunk cmd $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.sh --mode realtime
# This is normally not necessary as parsers will automatically detect if we are dealing with realtime data

[source::.../*.nmon]
invalid_cause = archive
unarchive_cmd = $SPLUNK_HOME/bin/splunk cmd $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.sh
sourcetype = nmon_processing
NO_BINARY_CHECK = true

# To manage repositories archives of cold nmon files (add you own for other compressed formats)
[source::.../*.nmon.gz]
invalid_cause = archive
unarchive_cmd = gunzip | $SPLUNK_HOME/bin/splunk cmd $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.sh
sourcetype = nmon_processing
NO_BINARY_CHECK = true

###########################################
#			nmon converted csv stanza			#
###########################################

# This sourcetype stanza will be used to index nmon csv converted data
# Every generated csv file will contain a CSV header used by Splunk to identify fields

[nmon_data]

FIELD_DELIMITER=,
FIELD_QUOTE="
HEADER_FIELD_LINE_NUMBER=1

# your settings
INDEXED_EXTRACTIONS=csv
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=false
TIMESTAMP_FIELDS=ZZZZ
TIME_FORMAT=%d-%m-%Y %H:%M:%S

# set by detected source type
KV_MODE=none
pulldown_type=true

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_data_hostoverride

# Automatically create the OStype field from nmon_inventory lookup
LOOKUP-OStype = nmon_inventory hostname AS hostname OUTPUTNEW OStype AS OStype

# A bug has affected string replacement in nmon2csv.py before V1.1.10
# This can lead the LPAR section cpu usage stated vs VP to be returned as null
# This alias will prevent the problem was previously indexed data
FIELDALIAS-VP_IdlePCT = VP_IdlePCT AS VP_Idle_PCT

### frameID ###

#
# NEW ! Starting with V1.5.0, use the frameID to automatically associate hosts with the Frame IDs, like associating AIX hosts with PSeries names for example
# In default configuration, the "frameid" will be equivalent to the host Serial Number using the above Alias

FIELDALIAS-frameID = serialnum AS frameID

# To create your custom association (automatic lookup)

# 1. Create a custom local/transforms.conf to configure your lookup table (see transforms.conf)
# 2. Create a custom local/props.conf with a [nmon_data] stanza
# 3. Configure your automatic lookup to overwrite the frameID field (use OUTPUT, don't use OUTPUTNEW which wont't overwrite the frameID field)

# LOOKUP-PSERIES = my_lookup_table serialnum AS serialnum OUTPUT PSERIES AS frameID

#####################
# CIM normalization #
#####################

# When applicabe, be CIMP compliant (see: http://docs.splunk.com/Documentation/CIM/4.3.1/User/Performance)
EVAL-hypervisor_id = if(isnotnull(frameID), frameID, serialnum)

# CIM normalization for common cpu metrics

EVAL-cpu_load_percent = (Sys_PCT+User_PCT+Wait_PCT)
FIELDALIAS-cpu_load_user = User_PCT as cpu_user_percent

# CIM normalization for common memory metrics

# Total memory available in MB (for AIX / Linux / Solaris)
EVAL-mem = case(isnotnull(Real_total_MB), Real_total_MB, isnotnull(memtotal), memtotal)
EVAL-mem_free = case(isnotnull(Real_free_MB), Real_free_MB, isnotnull(memfree), memfree)
EVAL-mem_used = case(isnotnull(Real_total_MB), (Real_total_MB-Real_free_MB), isnotnull(memtotal), (memtotal-memfree))

# Total virtual memory available in MB (for AIX / Linux / Solaris)
EVAL-swap = case(isnotnull(Virtual_total_MB), Virtual_total_MB, isnotnull(swaptotal), swaptotal)
EVAL-swap_free = case(isnotnull(Virtual_free_MB), Virtual_free_MB, isnotnull(swapfree), swapfree)
EVAL-swap_used = case(isnotnull(Virtual_total_MB), (Virtual_total_MB-Virtual_free_MB), isnotnull(swaptotal), (swaptotal-swapfree))

# CIM normalization for common network statistics
EVAL-thruput = case(type=="NET", (value*1000))

###########################################
#			nmon processing stanza				#
###########################################

[nmon_processing]

TIME_FORMAT=%d-%m-%Y %H:%M:%S

# Deactivate KV
KV_MODE = none

# For TA-nmon
EXTRACT-splunk_home = (?i).+\w*\sRoot\sDirectory\s\(\$SPLUNK_HOME\)\:\s{0,}(?P<splunk_home>[a-zA-Z0-9\/\\\-\_\.\:]+)\s

# For nmon-logger
EXTRACT-nmon_home = (?i).+\w*\sRoot\sDirectory\s\(\$NMON_VAR\)\:\s{0,}(?P<nmon_var>[a-zA-Z0-9\/\\\-\_\.\:]+)\s

EXTRACT-operating_system = (?i).+Guest\sOperating\sSystem\:\s{0,}(?P<operating_system>[a-zA-Z0-9]+)\s
EXTRACT-python_version = (?i).+Python\sversion\:\s{0,}(?P<python_version>[a-zA-Z0-9\.]+)\s
EXTRACT-perl_version = (?i).+Perl\sversion\:\s{0,}(?P<perl_version>[a-zA-Z0-9\.]+)\s
EVAL-converter_inuse = case(isnotnull(python_version), "Python", isnotnull(perl_version), "Perl")
EVAL-interpreter_version = case(isnotnull(python_version), python_version, isnotnull(perl_version), perl_version)
EXTRACT-nmon2csv_version = (?i).+nmon2csv\sversion\:\s{0,}(?P<nmon2csv_version>[0-9\.]+)\s
EXTRACT-hostname = (?i).+HOSTNAME\:\s{0,}(?P<hostname>[a-zA-Z0-9\-\_\.]+)
EXTRACT-nbr_lines = (?i).+Reading\sNMON\sdata:\s{0,}(?P<nbr_lines>\d+)\slines
EXTRACT-size_in_bytes = (?i).+lines\s(?P<size_in_bytes>\d+)\sbytes
EXTRACT-elapsed_in_seconds = (?i).+Elapsed\stime\swas\:\s{0,}(?P<elapsed_in_seconds>\d+\.\d+)\sseconds
EXTRACT-Nmon_version = (?i).+NMON\sVERSION\:\s{0,}(?P<Nmon_version>[a-zA-Z0-9\-\_\.\s]+)\s
EXTRACT-Time_of_Nmon_data = (?i).+TIME\sof\sNmon\sData\:\s{0,}(?P<Time_of_Nmon_Data>[0-9\:\.]+)\s
EXTRACT-Date_of_Nmon_data = (?i).+DATE\sof\sNmon\sData\:\s{0,}(?P<Date_of_Nmon_Data>[a-zA-Z0-9\-\/]+)\s
EXTRACT-INTERVAL = (?i).+INTERVAL\:\s{0,}(?P<INTERVAL>\d+)\s
EXTRACT-SNAPSHOTS = (?i).+SNAPSHOTS\:\s{0,}(?P<SNAPSHOTS>\d+)\s
EXTRACT-logical_cpus = (?i).+logical_cpus\:\s{0,}(?P<logical_cpus>\d+)\s
EXTRACT-virtual_cpus = (?i).+virtual_cpus\:\s{0,}(?P<virtual_cpus>\d+)\s
EXTRACT-Nmon_ID = (?i).+NMON\sID\:\s{0,}(?P<Nmon_ID>[a-zA-Z0-9\-\:\,\_\.]+)\s

###########################################
#			nmon config stanza					#
###########################################

[nmon_config]

BREAK_ONLY_BEFORE=CONFIG,
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%d-%b-%Y:%H:%M
TIME_PREFIX=CONFIG,
TRUNCATE=0

# Deactivate KV
KV_MODE = none

EXTRACT-hostname = (?i)AAA,host,(?P<hostname>[a-zA-Z0-9\-\_\.]+)\s

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_config_hostoverride

# Perform basic extractions
# Full extractions can be performed by calling associated macros, or using the data model
EXTRACT-OS = (?i),OS,(?P<OS>[^,]+)\s{0,}
EXTRACT-AIX_LEVEL = AAA,AIX,(?P<AIX_LEVEL>[a-zA-Z0-9\-\_\.]+)\s
EXTRACT-Linux_LEVEL = AAA,OS,Linux,(?P<Linux_LEVEL>[^,]+),
EXTRACT-Solaris_LEVEL = AAA,OS,Solaris,(?P<Solaris_LEVEL>[^,]+),
EVAL-OStype = case(OS == "Linux", "Linux", OS == "Solaris", "Solaris", isnotnull(AIX_LEVEL), "AIX", isnull(OS), "Unknown")

###########################################
#			SA-Eventgen								#
###########################################

# All these stanza are related to Eventgen configuration, for App testing purposes, Evengen will generate various sample data
# These settings can be safety ignored in Production systems as they will never affect anything as long as Eventgen inputs are not activated (deactivated by default)

[source::...AIX_CPU_ALL_sample.csv]
sourcetype = nmon_data
REPORT-AIX_CPU_ALL_sample = AIX_CPU_ALL_sample

[source::...AIX_LPAR_sample.csv]
sourcetype = nmon_data
REPORT-AIX_LPAR_sample = AIX_LPAR_sample

[source::...AIX_MEM_sample.csv]
sourcetype = nmon_data
REPORT-AIX_MEM_sample = AIX_MEM_sample

[source::...Linux_CPU_ALL_sample.csv]
sourcetype = nmon_data
REPORT-Linux_CPU_ALL_sample = Linux_CPU_ALL_sample

[source::...Linux_MEM_sample.csv]
sourcetype = nmon_data
REPORT-Linux_MEM_sample = Linux_MEM_sample

[source::...Linux_TOP_sample.csv]
sourcetype = nmon_data
REPORT-Linux_TOP_sample = Linux_TOP_sample

[source::...Solaris_CPU_ALL_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_CPU_ALL_sample = Solaris_CPU_ALL_sample

[source::...Solaris_MEM_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_MEM_sample = Solaris_MEM_sample

[source::...Solaris_TOP_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_TOP_sample = Solaris_TOP_sample

[source::...Solaris_WLM_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_WLM_sample = Solaris_WLM_sample

[source::...DISKXFER_sample.csv]
sourcetype = nmon_data
REPORT-DISKXFER_sample = DISKXFER_sample

##############################################
#			SYSLOG SPECIAL SECTIONS					#
##############################################

# These parameters are dedicated to the deployment of Nmon using syslog as the transport layer
# to forward Nmon Performance data from your end servers to your central syslog, and finally to Splunk

# Deploying Nmon with syslog requires additional configuration on search heads, and potentially indexers
# This also requires specific configuration on end clients (rsyslog/syslog-ng config, cron config, logrotate)

# Data being transferred through syslog is not csv structured data but key=value data
# each source of data is being in a temporary sourcetype for indexing time parsing to occur, then we will
# rewrite the sourcetypes to match standard sourcetypes being used by Core application

# depending on its origin (the source, normal vs syslog), the configuration on the sh head will apply the correct
# extraction parameters at search time.

# The nmon-logger package for Syslog deployment is available at:
# https://github.com/guilhemmarchand/nmon-logger

# Online guides for Syslog deployment:
# rsyslog: http://nmonsplunk.wikidot.com/documentation:installation:rsyslog
# syslog-ng: http://nmonsplunk.wikidot.com/documentation:installation:syslog-ng

####################
# Syslog to Splunk #
####################
#
# If you receive directly from syslog over TCP/UDP, use this sourcetype
# Create a dedicated UDP or TCP input with:
# index = nmon
# source = (leave optional or put anything you like)
# sourcetype = nmon:fromsyslog

# This sourcetype must manage incoming multi / or mono line event
# syslog timestamp is not being used for data time stamping (using nmon timestamp)

#
# Splunk to Splunk is not recommended, prefer having a Splunk instance installed on rsyslog collectors
# or on machine receiving rsyslog data, and generating local per host files
# Therefore, it is still possible to achieve it using a tcp/udp input using this sourcetype:

[nmon:fromsyslog]

BREAK_ONLY_BEFORE=timestamp="
MAX_EVENTS=100000
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
MAX_TIMESTAMP_LOOKAHEAD=26

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_collect
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

# Rewrite sourcetype to standard nmon_clean
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite

#####################################
# Splunk to Splunk with syslog data #
#####################################

# These sourcetypes will be used when reading local files generated by syslog from remote syslog clients 
# Each type of data must have its own file monitor.

# See inputs.conf.spec for more information, or read the online wiki manual pages for rsyslog / syslog-ng deployments

#
# For nmon performance data:
#

###################################################
# Set parameters for nmon_data coming from syslog #
###################################################

[nmon_data:fromsyslog]
SHOULD_LINEMERGE=false
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
MAX_TIMESTAMP_LOOKAHEAD=26
KV_MODE=auto

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# For search heads, activate kvmode to auto for that source
[source::perfdata:syslog]
KV_MODE=auto

#
# For nmon configuration data:
#

#####################################################
# Set parameters for nmon_config coming from syslog #
#####################################################

[nmon_config:fromsyslog]
BREAK_ONLY_BEFORE=timestamp="
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%s
TIME_PREFIX=timestamp="
TRUNCATE=0

# Deactivate KV
KV_MODE = none

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

#
# For nmon processing data:
#

[nmon_processing:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIME_PREFIX=nmon2csv:
CHARSET=UTF-8
BREAK_ONLY_BEFORE=nmon2csv:

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

#
# For nmon collecting data:
#

[nmon_collect:fromsyslog]

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_collect
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

#
# For nmon clean data:
#

[nmon_clean:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
BREAK_ONLY_BEFORE=Starting nmon cleaning
TIME_FORMAT=%c
TIME_PREFIX=\w*\s
CHARSET=UTF-8

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_clean
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite
