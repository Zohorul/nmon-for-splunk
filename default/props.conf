# props.conf

##################################
#			nmon2csv stanza			#
##################################

# IMPORTANT: Since the V1.6.0, the configuration uses the nmon2csv.sh wrapper that will call nmon2csv.py (prefered choice) or nmon2csv.pl if appropriated
# You can still force the configuration to use the Python or Perl converter (but the nmon2csv.sh wrapper will do the choice for you, enforcing the choice is not required anymore)

# *** BE UPGRADE RESILIENT: *** Copy this stanza to your local/props.conf to prevent futur upgrades from overwritting your setting 

# To use the Python converter, set:
# unarchive_cmd = $SPLUNK_HOME/bin/splunk cmd python $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.py

# To use the Perl converter, set:
# unarchive_cmd = $SPLUNK_HOME/etc/apps/TA-nmon/bin/nmon2csv.pl

# This source stanza will be called by the archive processor to convert NMON raw data into csv files
# SPlunk can manage. See inputs.conf for the associated monitor

# Since V1.6.14 of Nmon core app, default configuration enforces realtime mode for *.nmon files
[source::.../*.nmon]
invalid_cause = archive
unarchive_cmd = $SPLUNK_HOME/bin/splunk cmd $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.sh --mode realtime
sourcetype = nmon_processing
NO_BINARY_CHECK = true

# To manage repositories archives of cold nmon files (add you own for other compressed formats)
[source::.../*.nmon.gz]
invalid_cause = archive
unarchive_cmd = gunzip | $SPLUNK_HOME/bin/splunk cmd $SPLUNK_HOME/etc/apps/nmon/bin/nmon2csv.sh
sourcetype = nmon_processing
NO_BINARY_CHECK = true

###########################################
#			nmon converted csv stanza			#
###########################################

# This sourcetype stanza will be used to index nmon csv converted data
# Every generated csv file will contain a CSV header used by Splunk to identify fields

[nmon_data]

FIELD_DELIMITER=,
FIELD_QUOTE="
HEADER_FIELD_LINE_NUMBER=1

# your settings
INDEXED_EXTRACTIONS=csv
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=false
TIMESTAMP_FIELDS=ZZZZ
TIME_FORMAT=%d-%m-%Y %H:%M:%S

# set by detected source type
KV_MODE=none
pulldown_type=true

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_data_hostoverride

# Automatically create the OStype field from nmon_inventory lookup
LOOKUP-OStype = nmon_inventory hostname AS hostname OUTPUTNEW OStype AS OStype

# A bug has affected string replacement in nmon2csv.py before V1.1.10
# This can lead the LPAR section cpu usage stated vs VP to be returned as null
# This alias will prevent the problem was previously indexed data
FIELDALIAS-VP_IdlePCT = VP_IdlePCT AS VP_Idle_PCT

### frameID ###

#
# NEW ! Starting with V1.5.0, use the frameID to automatically associate hosts with the Frame IDs, like associating AIX hosts with PSeries names for example
# In default configuration, the "frameid" will be equivalent to the host Serial Number using the above Alias

FIELDALIAS-frameID = serialnum AS frameID

# To create your custom association (automatic lookup)

# 1. Create a custom local/transforms.conf to configure your lookup table (see transforms.conf)
# 2. Create a custom local/props.conf with a [nmon_data] stanza
# 3. Configure your automatic lookup to overwrite the frameID field (use OUTPUT, don't use OUTPUTNEW which wont't overwrite the frameID field)

# LOOKUP-PSERIES = my_lookup_table serialnum AS serialnum OUTPUT PSERIES AS frameID

###############

###########################################
#			nmon processing stanza				#
###########################################

[nmon_processing]

TIME_FORMAT=%d-%m-%Y %H:%M:%S

EXTRACT-splunk_home = (?i).+Splunk\sRoot\sDirectory\s\(\$SPLUNK_HOME\)\:\s(?P<splunk_home>[a-zA-Z0-9\/\\\-\_\.\:]+)\s
EXTRACT-operating_system = (?i).+Guest\sOperating\sSystem\:\s(?P<operating_system>[a-zA-Z0-9]+)\s
EXTRACT-python_version = (?i).+Python\sversion\:\s(?P<python_version>[a-zA-Z0-9\.]+)\s
EXTRACT-perl_version = (?i).+Perl\sversion\:\s(?P<perl_version>[a-zA-Z0-9\.]+)\s
EVAL-converter_inuse = case(isnotnull(python_version), "Python", isnotnull(perl_version), "Perl")
EVAL-interpreter_version = case(isnotnull(python_version), python_version, isnotnull(perl_version), perl_version)
EXTRACT-nmon2csv_version = (?i).+nmon2csv\sversion\:\s(?P<nmon2csv_version>[0-9\.]+)\s
EXTRACT-hostname = (?i).+HOSTNAME\:\s(?P<hostname>[a-zA-Z0-9\-\_\.]+)\s
EXTRACT-nbr_lines = (?i).+Reading\sNMON\sdata:\s(?P<nbr_lines>\d+)\slines
EXTRACT-size_in_bytes = (?i).+lines\s(?P<size_in_bytes>\d+)\sbytes
EXTRACT-elapsed_in_seconds = (?i).+Elapsed\stime\swas\:\s(?P<elapsed_in_seconds>\d+\.\d+)\sseconds
EXTRACT-Nmon_version = (?i).+NMON\sVERSION\:\s(?P<Nmon_version>[a-zA-Z0-9\-\_\.\s]+)\s
EXTRACT-Time_of_Nmon_data = (?i).+TIME\sof\sNmon\sData\:\s(?P<Time_of_Nmon_Data>[0-9\:\.]+)\s
EXTRACT-Date_of_Nmon_data = (?i).+DATE\sof\sNmon\sData\:\s(?P<Date_of_Nmon_Data>[a-zA-Z0-9\-\/]+)\s
EXTRACT-INTERVAL = (?i).+INTERVAL\:\s(?P<INTERVAL>\d+)\s
EXTRACT-SNAPSHOTS = (?i).+SNAPSHOTS\:\s(?P<SNAPSHOTS>\d+)\s
EXTRACT-logical_cpus = (?i).+logical_cpus\:\s(?P<logical_cpus>\d+)\s
EXTRACT-virtual_cpus = (?i).+virtual_cpus\:\s(?P<virtual_cpus>\d+)\s
EXTRACT-Nmon_ID = (?i).+NMON\sID\:\s(?P<Nmon_ID>[a-zA-Z0-9\-\:\,\_\.]+)\s


###########################################
#			nmon config stanza					#
###########################################

[nmon_config]

BREAK_ONLY_BEFORE=CONFIG,
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%d-%b-%Y:%H:%M
TIME_PREFIX=CONFIG,
TRUNCATE=0

EXTRACT-hostname = (?i)AAA,host,(?P<hostname>[a-zA-Z0-9\-\_\.]+)\s

# Overwritting default host field based on event data for nmon_data sourcetype (useful when managing Nmon central shares)
TRANSFORMS-hostfield=nmon_config_hostoverride

###########################################
#			SA-Eventgen								#
###########################################

# All these stanza are related to Eventgen configuration, for App testing purposes, Evengen will generate various sample data
# These settings can be safety ignored in Production systems as they will never affect anything as long as Eventgen inputs are not activated (deactivated by default)

[source::...AIX_CPU_ALL_sample.csv]
sourcetype = nmon_data
REPORT-AIX_CPU_ALL_sample = AIX_CPU_ALL_sample

[source::...AIX_LPAR_sample.csv]
sourcetype = nmon_data
REPORT-AIX_LPAR_sample = AIX_LPAR_sample

[source::...AIX_MEM_sample.csv]
sourcetype = nmon_data
REPORT-AIX_MEM_sample = AIX_MEM_sample

[source::...Linux_CPU_ALL_sample.csv]
sourcetype = nmon_data
REPORT-Linux_CPU_ALL_sample = Linux_CPU_ALL_sample

[source::...Linux_MEM_sample.csv]
sourcetype = nmon_data
REPORT-Linux_MEM_sample = Linux_MEM_sample

[source::...Linux_TOP_sample.csv]
sourcetype = nmon_data
REPORT-Linux_TOP_sample = Linux_TOP_sample

[source::...Solaris_CPU_ALL_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_CPU_ALL_sample = Solaris_CPU_ALL_sample

[source::...Solaris_MEM_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_MEM_sample = Solaris_MEM_sample

[source::...Solaris_TOP_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_TOP_sample = Solaris_TOP_sample

[source::...Solaris_WLM_sample.csv]
sourcetype = nmon_data
REPORT-Solaris_WLM_sample = Solaris_WLM_sample

[source::...DISKXFER_sample.csv]
sourcetype = nmon_data
REPORT-DISKXFER_sample = DISKXFER_sample

##############################################
#			SYSLOG SPECIAL SECTIONS					#
##############################################

# These parameters are dedicated to the deployment of Nmon using syslog as the transport layer
# to forward Nmon Performance data from your end servers to your central syslog, and finally to Splunk

# Deploying Nmon with syslog requires additional configuration on search heads, and potentially indexers
# This also requires specific configuration on end clients (syslog config, cron config, logrotate)

# Data being transfered through syslog is not csv structured data but key=value data
# each source of data is being in a temporary sourcetype for indexing time parsing to occur, then we will
# rewrite the sourcetypes to match standard sourcetypes being used by Core application

# depending on its origin (the source, normal vs syslog), the configuration on the sh head will apply the correct
# extraction parameters at search time.

# See the README file at the root if this package, or read the online guide for Syslog deployment:

#
# For nmon performance data:
#

###################################################
# Set parameters for nmon_data coming from syslog #
###################################################

[nmon_data:fromsyslog]
SHOULD_LINEMERGE=false
NO_BINARY_CHECK=true
CHARSET=UTF-8
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIME_PREFIX=ZZZZ="
MAX_TIMESTAMP_LOOKAHEAD=26
KV_MODE=auto

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_data
TRANSFORMS-perfdata_fromsyslog = nmon_data_fromsyslog_rewrite

# For search heads, activate kvmode to auto for that source
[source::perfdata:syslog]
KV_MODE=auto

#
# For nmon configuration data:
#

#####################################################
# Set parameters for nmon_config coming from syslog #
#####################################################

[nmon_config:fromsyslog]
BREAK_ONLY_BEFORE=CONFIG,
MAX_EVENTS=100000
NO_BINARY_CHECK=1
SHOULD_LINEMERGE=true
TIME_FORMAT=%d-%b-%Y:%H:%M
TIME_PREFIX=CONFIG,
TRUNCATE=0

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-configdata_fromsyslog = nmon_config_fromsyslog_rewrite

#
# For nmon processing data:
#

[nmon_processing:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
TIME_FORMAT=%d-%m-%Y %H:%M:%S
TIME_PREFIX=\w*\s
CHARSET=UTF-8
BREAK_ONLY_BEFORE=Reading NMON data:

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_processing
TRANSFORMS-processingdata_fromsyslog = nmon_processing_fromsyslog_rewrite

#
# For nmon collecting data:
#

[nmon_collect:fromsyslog]

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-collectdata_fromsyslog = nmon_collect_fromsyslog_rewrite

#
# For nmon clean data:
#

[nmon_clean:fromsyslog]
SHOULD_LINEMERGE=true
NO_BINARY_CHECK=true
BREAK_ONLY_BEFORE=Starting nmon cleaning
TIME_FORMAT=%c
TIME_PREFIX=\w*\s
CHARSET=UTF-8

# Rewrite host Metadata using standard syslog rewrite
TRANSFORMS = syslog-host

# Rewrite sourcetype to standard nmon_config
TRANSFORMS-cleandata_fromsyslog = nmon_clean_fromsyslog_rewrite
